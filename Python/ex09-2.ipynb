{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習9.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDBデータは映画のレビューに対して、P/N(肯定/否定)のラベルが付いた学習データです。学習用に25000事例、評価用に25000事例用意されていて、PNの割合はそれぞれ50%です。\n",
    "各レビューは単語列ではなく、単語インデックスの系列として表現されています。\n",
    "\n",
    "ここでは、頻度上位10000語を対象とし、データの大きさは先頭の20単語に限定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\araki\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import preprocessing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense\n",
    "max_features = 10000\n",
    "maxlen = 20\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "X_train = preprocessing.sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = preprocessing.sequence.pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単語インデックスを単語に戻して、元のデータを確認します。インデックスは\"padding\", \"start of sequence\",\"unknown\"にそれぞれ0,1,2が割り当てられているので、3つずらして対応させます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in X_train[0]])\n",
    "decoded_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単純なRNNを構成して学習させます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 0.6073 - acc: 0.6509 - val_loss: 0.5781 - val_acc: 0.6934\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 2s 83us/step - loss: 0.4414 - acc: 0.7965 - val_loss: 0.5283 - val_acc: 0.7338\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 2s 82us/step - loss: 0.3491 - acc: 0.8486 - val_loss: 0.5589 - val_acc: 0.7106\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 2s 85us/step - loss: 0.2602 - acc: 0.8959 - val_loss: 0.6102 - val_acc: 0.7300\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 2s 83us/step - loss: 0.1784 - acc: 0.9313 - val_loss: 0.7045 - val_acc: 0.7154\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 2s 85us/step - loss: 0.1168 - acc: 0.9582 - val_loss: 0.7703 - val_acc: 0.7108\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 2s 86us/step - loss: 0.0683 - acc: 0.9781 - val_loss: 0.9151 - val_acc: 0.7052\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 2s 99us/step - loss: 0.0392 - acc: 0.9879 - val_loss: 1.0722 - val_acc: 0.7094\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 2s 93us/step - loss: 0.0195 - acc: 0.9947 - val_loss: 1.2693 - val_acc: 0.6768\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 2s 92us/step - loss: 0.0108 - acc: 0.9973 - val_loss: 1.3219 - val_acc: 0.6922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x149e0cbdc88>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=128,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.321589437561035\n",
      "Test accuracy: 0.69788\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNユニットをLSTMに変更して性能の変化を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 5s 268us/step - loss: 0.5843 - acc: 0.6873 - val_loss: 0.5195 - val_acc: 0.7434\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 4s 214us/step - loss: 0.4436 - acc: 0.7942 - val_loss: 0.4994 - val_acc: 0.7566\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 4s 209us/step - loss: 0.3960 - acc: 0.8226 - val_loss: 0.4878 - val_acc: 0.7550\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 4s 203us/step - loss: 0.3694 - acc: 0.8361 - val_loss: 0.5104 - val_acc: 0.7478\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 4s 218us/step - loss: 0.3506 - acc: 0.8476 - val_loss: 0.5043 - val_acc: 0.7484\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 5s 237us/step - loss: 0.3355 - acc: 0.8539 - val_loss: 0.5490 - val_acc: 0.7504\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 4s 221us/step - loss: 0.3225 - acc: 0.8620 - val_loss: 0.5150 - val_acc: 0.7474\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 4s 211us/step - loss: 0.3087 - acc: 0.8690 - val_loss: 0.5417 - val_acc: 0.7380\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 5s 233us/step - loss: 0.2949 - acc: 0.8750 - val_loss: 0.5623 - val_acc: 0.7452\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 4s 204us/step - loss: 0.2813 - acc: 0.8811 - val_loss: 0.5952 - val_acc: 0.7398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x149e3876a90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=128,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5906619605827331\n",
      "Test accuracy: 0.74824\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
