{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習9.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "警告を非表示に"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDBデータは映画のレビューに対して、P/N(肯定/否定)のラベルが付いた学習データです。学習用に25000事例、評価用に25000事例用意されていて、PNの割合はそれぞれ50%です。\n",
    "各レビューは単語列ではなく、単語インデックスの系列として表現されています。\n",
    "\n",
    "ここでは、頻度上位10000語を対象とし、データの大きさは先頭の20単語に限定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import preprocessing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense\n",
    "max_features = 10000\n",
    "maxlen = 20\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "X_train = preprocessing.sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = preprocessing.sequence.pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単語インデックスを単語に戻して、元のデータを確認します。インデックスは\"padding\", \"start of sequence\",\"unknown\"にそれぞれ0,1,2が割り当てられているので、3つずらして対応させます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in X_train[0]])\n",
    "decoded_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単純なRNNを構成して学習させます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 1s 69us/step - loss: 0.6073 - acc: 0.6509 - val_loss: 0.5779 - val_acc: 0.6936\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 1s 61us/step - loss: 0.4414 - acc: 0.7965 - val_loss: 0.5283 - val_acc: 0.7338\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 1s 61us/step - loss: 0.3491 - acc: 0.8484 - val_loss: 0.5590 - val_acc: 0.7108\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 1s 62us/step - loss: 0.2602 - acc: 0.8959 - val_loss: 0.6101 - val_acc: 0.7296\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 1s 63us/step - loss: 0.1784 - acc: 0.9312 - val_loss: 0.7043 - val_acc: 0.7154\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 1s 59us/step - loss: 0.1169 - acc: 0.9582 - val_loss: 0.7705 - val_acc: 0.7110\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 1s 59us/step - loss: 0.0683 - acc: 0.9781 - val_loss: 0.9151 - val_acc: 0.7058\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 1s 59us/step - loss: 0.0392 - acc: 0.9879 - val_loss: 1.0707 - val_acc: 0.7088\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 1s 59us/step - loss: 0.0195 - acc: 0.9946 - val_loss: 1.2695 - val_acc: 0.6774\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 1s 59us/step - loss: 0.0108 - acc: 0.9974 - val_loss: 1.3222 - val_acc: 0.6906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2df814807b8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=128,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.3222395536994933\n",
      "Test accuracy: 0.69772\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNユニットをLSTMに変更して性能の変化を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 3s 140us/step - loss: 0.5843 - acc: 0.6873 - val_loss: 0.5195 - val_acc: 0.7432\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 0.4436 - acc: 0.7943 - val_loss: 0.4994 - val_acc: 0.7566\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 0.3959 - acc: 0.8226 - val_loss: 0.4878 - val_acc: 0.7548\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 0.3694 - acc: 0.8361 - val_loss: 0.5104 - val_acc: 0.7478\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 0.3506 - acc: 0.8476 - val_loss: 0.5043 - val_acc: 0.7484\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 0.3355 - acc: 0.8538 - val_loss: 0.5490 - val_acc: 0.7504\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 0.3225 - acc: 0.8620 - val_loss: 0.5150 - val_acc: 0.7474\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 0.3087 - acc: 0.8690 - val_loss: 0.5417 - val_acc: 0.7380\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 3s 127us/step - loss: 0.2949 - acc: 0.8750 - val_loss: 0.5623 - val_acc: 0.7452\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 0.2813 - acc: 0.8811 - val_loss: 0.5952 - val_acc: 0.7398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2df831f7cf8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=128,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.590690350780487\n",
      "Test accuracy: 0.74824\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
